# [Apache Spark SQL for Data Analysts](https://www.coursera.org/learn/apache-spark-sql-for-data-analysts/home/welcome)

### Tools and Technologys

* Apache SQL
* Databricks community edition 
* Relational Databases and SQL
* Datawarehouse and Delta lakes

The following are the the two core objectives of the course

* Leverage existing SQL skills to start working with Apache Spark. 
* Be able to use Spark SQL and Delta Lake to ingest, transform, and query data to extract valuable insights
* 

### Course Organization

[Week 1]()

An introduction to this course including learning objectives, frequently asked questions, and a chance to get to know fellow classmates.

[Week 2]()

* Describe the characteristics that define big data.
* Identify common struggles data analysts face when working with big data.
* Describe tools data analysts use to work with big data

[Week 3]()
 
* Prepare the Databricks workspace for running data workflows
* Use Databricks notebooks to run Spark SQL queries.
* Use Databricks notebooks to visualize data.


[Week 4]()
* Describe how Spark manages data workloads and optimizes queries.
* Summarize how Apache Spark optimizes queries.
* Locate evidence of Sparkâ€™s underlying optimization features in the Spark UI

[Week 5]()

* Use common design patterns for complex queries and creating tables and views.
* Use Databricks to manage and modify nested data structures.
* Use Databricks to prepare data for queries.

[Week 6]()

* Practice advanced SQL functions to manipulate and present complex data.
* Use Spark SQL higher-order functions to transform and aggregate data.
* Practice a variety of aggregation and summary techniques to work with data

[Week 7]()
* Compare Data Warehouses and Data Lakes
* Describe common challenges for Data Lakes and Data Warehouses
* Define a Lakehouse


[Week 8]()

* Identify and correct records in a central data lake.
* Clean and prepare data for and aggregated table
* Write data to a delta table

[Week 9]()

* Use Databricks notebooks to run Spark SQL queries.
* Practice advanced SQL functions to manipulate and present complex data.
* Use Spark SQL higher-order functions to transform and aggregate data.


